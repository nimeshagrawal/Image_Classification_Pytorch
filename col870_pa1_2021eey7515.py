# -*- coding: utf-8 -*-
"""COL870_PA1_2021EEY7515.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xTR5Z-fgRXLfV2U6zJGbR6wISV4hPx0H
"""

import torch, os
import torchvision
import torchvision.transforms as transforms
from tqdm import tqdm
import numpy as np
import matplotlib.pyplot as plt
import random
from google.colab import drive
drive.mount('/content/gdrive')

########################################################################
# The output of torchvision datasets are PILImage images of range [0, 1].

# Apply necessary image transfromations here

!unzip gdrive/MyDrive/3.zip

def get_default_device():
  if torch.cuda.is_available():
    return torch.device('cuda')
  else:
    return torch.device('cpu')
device = get_default_device()
device

transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0,0,0], std=[1, 1, 1])])



train_data_dir = '/content/3/train' # put path of training dataset
val_data_dir = '/content/3/val' # put path of test dataset
test_data_dir = '/content/3/test' # put path of test dataset

batch_size = 100 
trainset = torchvision.datasets.ImageFolder(root= train_data_dir, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                          shuffle=True, num_workers=2)

valnset = torchvision.datasets.ImageFolder(root= val_data_dir, transform=transform)
valloader = torch.utils.data.DataLoader(valnset, batch_size=batch_size,
                                          shuffle= False, num_workers=2)

testset = torchvision.datasets.ImageFolder(root= test_data_dir, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size,
                                         shuffle=False, num_workers=2)


########################################################################
# Define a Convolution Neural Network
# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
# Copy the neural network from the Neural Networks section before and modify it to
# take 3-channel images (instead of 1-channel images as it was defined).

img, label = trainset[1500]
print(img.shape, label)
print(trainset.classes)

def show_example(img, label):
  print("Label: " , trainset.classes[label], "(" + str(label) + ")")
  plt.imshow(img.permute(1,2,0))

show_example(*trainset[5000])

import torch.nn as nn
import torch.nn.functional as F
import torchvision.models as models

# <<<<<<<<<<<<<<<<<<<<< EDIT THE MODEL DEFINITION >>>>>>>>>>>>>>>>>>>>>>>>>>
# Try experimenting by changing the following:
# 1. number of feature maps in conv layer
# 2. Number of conv layers
# 3. Kernel size
# etc etc.,

num_epochs = 50      # desired number of training epochs.
learning_rate = 0.01   

class Net1(nn.Module):
    def __init__(self):
        super(Net1, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size = 5, stride = 2,padding=1)
        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5,stride = 2, padding=1)
        self.conv3 = nn.Conv2d(in_channels= 32, out_channels=64, kernel_size=3,stride = 1, padding=1)
  

        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.dropout1 = nn.Dropout(0.5)
        self.fc1 = nn.Linear(in_features=256, out_features=512)
        self.fc2 = nn.Linear(in_features=512, out_features=33)


    def forward(self, x): 
        #print(x.shape)
        x = F.relu(self.conv1(x))
        #print(x.shape)
        x = self.pool(x)
        #print(x.shape)
        
        x = F.relu(self.conv2(x))
        #print(x.shape)
        x = self.pool(x)
        #print(x.shape)
        
        x = F.relu(self.conv3(x))
        #print(x.shape)
        x = self.pool(x)
        #print(x.shape)
        
        #x = F.relu(self.conv4(x))
        #x = self.pool(x)
        
        #x = F.relu(self.conv5(x))
        #x = self.pool(x)

        #x = F.avg_pool2d(x, kernel_size=x.shape[2:])
        x = x.view(x.shape[0], -1)
        #print(x.shape)
        x = F.relu(self.fc1(x))
        #print(x.shape)
        x = self.dropout1(x)
        #print(x.shape)
        #print(x.shape)
        #x = F.relu(self.fc2(x))
        #x = self.dropout1(x)
        x = self.fc2(x)
        #print(x)
        #x = F.softmax(x)
        #print(x.shape)
        
        return x 


class Net2(nn.Module):
    def __init__(self):
        super(Net2, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size = 3, stride = 1,padding=1)
        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3,stride = 1, padding=1)
        self.conv3 = nn.Conv2d(in_channels= 32, out_channels=64, kernel_size=3,stride = 1, padding=1)
  

        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.dropout1 = nn.Dropout(0.5)
 
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        
        self.linear_block = nn.Sequential(

            nn.Linear(64, 512),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(512, 128),
            nn.ReLU(),
            nn.Linear(128, 33)
        )

    def forward(self, x):

        x = self.pool(self.pool(F.relu(self.conv1(x))))
        x = self.pool(self.pool(F.relu(self.conv2(x))))
        x = self.pool(self.pool(F.relu(self.conv3(x))))


        x = x.view(x.shape[0],-1)
        x = self.linear_block(x)
        
        
        return x



class Net3(nn.Module): 
        def __init__(self):
          super(Net3, self).__init__()
          self.conv1 = nn.Conv2d(3,16,3,1,1)
          self.conv2 = nn.Conv2d(16,32,3,1,1)
         
          self.conv_block1 = nn.Sequential(
              nn.Conv2d(32, 64, 3, 1, 1),
              nn.BatchNorm2d(64),
              nn.ReLU(),
              nn.Conv2d(64, 64, 3, 1, 1),
              nn.BatchNorm2d(64),
              nn.ReLU()
          )
          self.conv_block2 = nn.Sequential(
              nn.Conv2d(64, 128, 3, 1, 1),
              nn.BatchNorm2d(128),
              nn.ReLU(),
              nn.Conv2d(128, 128, 3, 1, 1),
              nn.BatchNorm2d(128),
              nn.ReLU()
          )

          self.conv_block3 = nn.Sequential(
              nn.Conv2d(128, 256, 3,1,1),
              nn.BatchNorm2d(256),
              nn.ReLU(),
              nn.Conv2d(256, 256, 3, 1,1),
              nn.BatchNorm2d(256),
              nn.ReLU(),
              
          )

        

          self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
          
          self.linear_block = nn.Sequential(

              nn.Linear(1024, 512),
              nn.ReLU(),
              nn.Dropout(0.5),
              nn.Linear(512, 128),
              nn.ReLU(),
              nn.Linear(128, 33)
          )

        def forward(self, x):

          x = self.pool(F.relu(self.conv1(x)))
          x = self.pool(F.relu(self.conv2(x)))
      
          x = self.pool(self.conv_block1(x))
          x = self.pool(self.conv_block2(x))
          x = self.pool(self.conv_block3(x))
      

          x = x.view(x.shape[0],-1)
          x = self.linear_block(x)
        
        
          return x

################### DO NOT EDIT THE BELOW CODE!!! #######################

net = Net2()

# transfer the model to GPU
if torch.cuda.is_available():
    net = net.cuda()

########################################################################
# Define a Loss function and optimizer
# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
# Let's use a Classification Cross-Entropy loss and SGD with momentum.

import torch.optim as optim
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)

num_params = np.sum([p.nelement() for p in net.parameters()])
print(num_params, ' parameters')

from torchsummary import summary
summary(net,(3,84,84))

########################################################################
# Train the network
# ^^^^^^^^^^^^^^^^^^^^
from matplotlib.ticker import MaxNLocator
def train(epoch, trainloader,net, optimizer, criterion):
    running_loss = 0.0

    correct=0
    total=0
    
    for i, data in enumerate(tqdm(trainloader), 0):
        # get the inputs
        inputs, labels = data
        if torch.cuda.is_available():
            inputs, labels = inputs.cuda(), labels.cuda()

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        #print("Outputs",outputs)
        #print("Labels", labels)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
    running_loss = running_loss / (len(trainloader))
    running_acc = (100 * correct / total)
    print('epoch %d training loss: %.3f, acc: %d' %
            (epoch + 1, running_loss, running_acc))
    return running_loss, running_acc
        
    
    
########################################################################
# Let us look at how the network performs on the test dataset.

def test(testloader, model,criterion):
    running_loss = 0
    correct = 0
    total = 0
    with torch.no_grad():
        for data in tqdm(testloader):
            images, labels = data
            if torch.cuda.is_available():
                images, labels = images.cuda(), labels.cuda()        
            outputs = model(images)
            loss = criterion(outputs, labels)

            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    running_loss = running_loss / (len(testloader))
    running_acc = (100 * correct / total)
    print('test error: %.3f, accuracy: %d' % (running_loss, running_acc))
    return running_loss, running_acc


def trainModel(model_name, net, num_epochs, optimizer, criterion):
    
    print("Started Training %s" % (model_name))

    
    train_loss = []
    train_acc = []
    val_loss = []
    val_acc = []

    for epoch in range(num_epochs): 
        print('epoch ', epoch + 1)
        epoch_train_loss, epoch_train_acc = train(epoch, trainloader, net, optimizer, criterion)
        net.eval()
        epoch_val_loss, epoch_val_acc = test(valloader, net, criterion)
        classwise_test(valloader, net)
        
        train_loss.append(epoch_train_loss)
        train_acc.append(epoch_train_acc)

        val_loss.append(epoch_val_loss)
        val_acc.append(epoch_val_acc)

        net.train()
        if ((epoch + 1) % 5 == 0) :
            model_path = 'gdrive/MyDrive/models/'+str(model_name)+'_'+str(epoch+1)+'.pth'
            torch.save({'epoch':epoch,
                        'model_state_dict':net.state_dict() }, model_path)
    
    # Plot and save loss curve and accuracy curve

    print("Saving loss curves")
    plotCurve(model_name, train_loss, train_acc, val_loss, val_acc)
    
    print('Performing Test')
    test(testloader, net, criterion)
    classwise_test(testloader, net)

    print('Finished Training %s' % (model_name))


#########################################################################
# get details of classes and class to index mapping in a directory
def find_classes(dir):
    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]
    classes.sort()
    class_to_idx = {classes[i]: i for i in range(len(classes))}
    return classes, class_to_idx


def classwise_test(testloader, model):
########################################################################
# class-wise accuracy

    classes, _ = find_classes(train_data_dir)
    n_class = len(classes) # number of classes

    class_correct = list(0. for i in range(n_class))
    class_total = list(0. for i in range(n_class))
    with torch.no_grad():
        for data in tqdm(testloader):
            images, labels = data
            #print("Shape", labels.shape)
            if torch.cuda.is_available():
                images, labels = images.cuda(), labels.cuda()        
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            c = (predicted == labels).squeeze()
            for i in range(batch_size):
                label = labels[i]
                class_correct[label] += c[i].item()
                class_total[label] += 1

    for i in range(n_class):
        print('Accuracy of %10s : %2f %%' % (
            classes[i], 100 * class_correct[i] / class_total[i]))

def plotCurve(model_name, training_loss, training_acc, validation_loss, validation_acc):

    ar = 1 + np.arange(len(training_loss))
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), tight_layout=True)

    ax1.plot(ar, training_loss, label = "training loss")
    ax1.plot(ar, validation_loss, label = "validation loss")
    ax1.set_xlabel("epochs")
    ax1.set_ylabel("error")
    ax1.legend()
    ax1.set_title("Loss Curve %s " %(model_name))

    ax2.plot(ar, training_acc, label = "training accuracy")
    ax2.plot(ar, validation_acc, label = "validation accuracy")
    ax2.set_xlabel("epochs")
    ax2.set_ylabel("Accuracy")
    ax2.legend()
    ax2.set_title("Accuracy Curve %s " %(model_name))

    plt.savefig('gdrive/MyDrive/images_occlusion/'+model_name+'.png')

os.makedirs('gdrive/MyDrive/models', exist_ok=True)

model_name = "Net4"
    
trainModel(model_name, net, num_epochs, optimizer, criterion)

model_path = 'gdrive/MyDrive/models/Net2_50.pth'

if torch.cuda.is_available():
    checkpoint = torch.load(f=model_path)
else:
    checkpoint = torch.load(f=model_path, map_location=torch.device('cpu'))

net = Net2()
net.load_state_dict(checkpoint['model_state_dict'])
net.eval()
epoch = checkpoint['epoch'] + 1

def occluded(net, img, label, kernel_size):
    
    width, height = img.shape[-1], img.shape[-2]
    
    confidence = torch.zeros((height-kernel_size+1, width-kernel_size+1))
    
    for i in tqdm(range(height-kernel_size+1)):
        bottom = i+kernel_size
        for j in range(width-kernel_size+1):
            right = j+kernel_size
            
            #grayscale img tensor in required window
            img_clone = img.clone().detach()
          
            img_clone[:, :, i:bottom, j:right] = 0
          
            #run inference on modified image
            output = net(img_clone)

            #convert loss to probability
            output = F.softmax(output, dim=1)

            confidence[i, j] = output[0][label]
    
    return confidence

def imageplot(img, ax, title=None):
     
    npimg = img.cpu().numpy()
  
    ax.axis("off")
    ax.imshow(np.transpose(npimg, (1, 2, 0)))
    if title!=None:
        ax.set_title(title)


def accuracy(net, testloader):
    c = None
    with torch.no_grad():
        for data in tqdm(testloader):
            images, labels = data
            if torch.cuda.is_available():
                images, labels = images.cuda(), labels.cuda()
            outputs = net(images)
            _,predicted = torch.max(outputs,1)
            c_batch = (predicted==labels).squeeze().int()
            if c==None:
                c=c_batch
            else:
                c=torch.cat((c,c_batch),dim=0)
    return c

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
os.makedirs('gdrive/MyDrive/images_occlusion', exist_ok=True)

transform = transforms.Compose([transforms.ToTensor(),
                                transforms.Normalize(mean=[0,0,0], std=[1, 1, 1])])

test_data_dir = '/content/3/test' 
testset = torchvision.datasets.ImageFolder(root= test_data_dir, transform=transform)

subset_indices = np.random.randint(3300,size=10) #select 10 images
subset = torch.utils.data.Subset(testset, subset_indices)

evalloader = torch.utils.data.DataLoader(subset, batch_size=1, shuffle=False)
evaliter = iter(evalloader)
classes, _ = find_classes(test_data_dir)


kernel_size = [10, 20]

cols = ['Kernel size = {}'.format(k) for k in kernel_size]
fig_fname = 'gdrive/MyDrive/images_occlusion/Occlusion_heatmaps2(Net2).png'
fig, axes = plt.subplots(nrows = len(subset), ncols=3, figsize=(9,3*len(subset)))

for i in range(len(kernel_size)):
    axes[0,(i+1)].set_title(cols[i])
    
idx=0
with torch.no_grad():   
    for data in evalloader:
        image, label = data
        
        imageplot(image[0],axes[idx,0],classes[label])
        
        idy=1
        for k in kernel_size:
            
            confidence = occluded(net, image, label, k)
            sns.heatmap(confidence, vmin=0, vmax=1,xticklabels=False,yticklabels=False,
                        ax=axes[idx,idy], square=True)
            idy+=1
            
        idx+=1  

plt.savefig(fig_fname, bbox_inches='tight')
plt.show()

model_path = 'gdrive/MyDrive/models/Net2_50.pth'

if torch.cuda.is_available():
    checkpoint = torch.load(f=model_path)
else:
    checkpoint = torch.load(f=model_path, map_location=torch.device('cpu'))

net = Net2()
if torch.cuda.is_available():
    net = net.cuda()

net.load_state_dict(checkpoint['model_state_dict'])
net.eval()
epoch = checkpoint['epoch'] + 1



transform = transforms.Compose([transforms.ToTensor(),
                                transforms.Normalize(mean=[0,0,0], std=[1, 1, 1])])

test_data_dir = '/content/3/test' 
testset = torchvision.datasets.ImageFolder(root = test_data_dir, transform=transform)
evalloader = torch.utils.data.DataLoader(testset, batch_size=100, num_workers=2, shuffle=False)


activation = {}
def get_activation(name):
    def hook(model, inp, out):
        activation[name] = out.detach()
    return hook

net.conv1.register_forward_hook(get_activation('conv1'))
net.conv2.register_forward_hook(get_activation('conv2'))
net.conv3.register_forward_hook(get_activation('conv3'))


def filters(net, testloader, filter_id, layer_name):
    act = None
    with torch.no_grad():
        for data in tqdm(testloader):
            images, labels = data
            if torch.cuda.is_available():
                images, labels = images.cuda(), labels.cuda()
            
            output = net(images)
            act_b = activation[layer_name][:,filter_id]
            if act == None:
                act = act_b
            else:
                act = torch.cat((act, act_b),dim=0)
    return act


import matplotlib.pyplot as plt

classes, _  = find_classes(test_data_dir)

layer_names = ['conv1', 'conv2', 'conv3']
filter_idx = {'conv1' : [7,15], 'conv2' : [10,30], 'conv3' : [9,55]}

for l in layer_names:
    for f in filter_idx[l]:
        act = filters(net, evalloader, f, l)
        print(act.shape)
        act_idx = torch.argsort(torch.Tensor([act[i].norm() for i in range(act.shape[0])]),descending=False)
        fig,axes = plt.subplots(nrows=2, ncols=5, figsize=(15,6))
        for i in range(5):
            imageplot((act[act_idx[i]])[None,:,:].resize_(3,84,84),axes[0,i])
            img, label = evalloader.dataset[act_idx[i]]
            imageplot(img,axes[1,i],classes[label])
        plot_name = l + '_filter' + str(f)
        plt.suptitle(plot_name)
        plt.savefig('gdrive/MyDrive/images_occlusion/'+plot_name+'.png')
        plt.show()


acc_on = accuracy(net,evalloader)
acc_on

with torch.no_grad():
  net.conv1.weight[7]=0
  net.conv1.weight[15]=0

  net.conv2.weight[10]=0
  net.conv2.weight[30]=0

  net.conv3.weight[9]=0
  net.conv3.weight[55]=0


acc_off = accuracy(net,evalloader)

cnt=0
img_idx = []
for i in range(len(evalloader.dataset)):
    if acc_on[i]==1 and acc_off[i]==0:
        cnt+=1
        img_idx.append(i)


n_class=33
classwise_error = list(0. for i in range(n_class))
for idx in img_idx:
    classwise_error[evalloader.dataset[idx][1]]+=1
    
for i in range(n_class):
    print("%15s : %d images"%(classes[i],classwise_error[i]))

